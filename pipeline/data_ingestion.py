# pipeline/data_ingestion.py

import os
from dotenv import load_dotenv

from core.crawler import crawl_multiple_domains
from core.html_downloader import download_all_html_from_file
from core.parser import parse_all_html
from core.embedder import embed_documents

load_dotenv()

SEED_URLS = [
    "https://docs.blender.org/manual/en/4.0/index.html",
    "https://helpx.adobe.com/photoshop/user-guide.html"
]

LINK_FILE = os.getenv("LINK_FILE", "all_links.txt")

def run_data_ingestion(seed_urls=SEED_URLS):
    print("ğŸ”— [1/4] ë§í¬ ìˆ˜ì§‘ ì¤‘...")
    crawl_multiple_domains(seed_urls, output_file=LINK_FILE)

    print("ğŸŒ [2/4] HTML ë‹¤ìš´ë¡œë“œ ì¤‘...")
    download_all_html_from_file(LINK_FILE)

    print("ğŸ“ [3/4] í…ìŠ¤íŠ¸ ì¶”ì¶œ ì¤‘...")
    parse_all_html()

    print("ğŸ§  [4/4] ë¬¸ì„œ ì„ë² ë”© ì¤‘...")
    embed_documents()

    print("âœ… ì „ì²´ ë°ì´í„° ì¸ì œìŠ¤íŠ¸ ì™„ë£Œ!")

if __name__ == "__main__":
    run_data_ingestion()
