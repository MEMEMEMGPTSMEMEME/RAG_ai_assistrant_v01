# core/embedder.py

import os
import faiss
import pickle
from dotenv import load_dotenv
from sentence_transformers import SentenceTransformer
from tqdm import tqdm

load_dotenv()

TEXT_DIR = os.getenv("TEXT_DIR", "storage/parsed_docs")
VECTOR_DIR = os.getenv("VECTOR_DIR", "storage/vector_store")
MODEL_NAME = os.getenv("MODEL_NAME", "all-MiniLM-L6-v2")

INDEX_PATH = os.path.join(VECTOR_DIR, "faiss_index.index")
METADATA_PATH = os.path.join(VECTOR_DIR, "metadata.pkl")


def load_text_files(directory):
    texts, metadata = [], []
    for filename in os.listdir(directory):
        if filename.endswith(".txt"):
            path = os.path.join(directory, filename)
            try:
                with open(path, "r", encoding="utf-8") as f:
                    content = f.read().strip()
                    if content:
                        texts.append(content)
                        metadata.append({"filename": filename})
            except Exception as e:
                print(f"[ERROR] íŒŒì¼ ì—´ê¸° ì‹¤íŒ¨: {filename} ({e})")
    return texts, metadata


def save_embeddings(index, metadata):
    os.makedirs(VECTOR_DIR, exist_ok=True)
    faiss.write_index(index, INDEX_PATH)
    with open(METADATA_PATH, "wb") as f:
        pickle.dump(metadata, f)
    print(f"âœ… FAISS ì¸ë±ìŠ¤ ì €ì¥ ì™„ë£Œ â†’ {INDEX_PATH}")


def embed_documents():
    print(f"ğŸ§  ì„ë² ë”© ëª¨ë¸ ë¡œë”© ì¤‘: {MODEL_NAME}")
    model = SentenceTransformer(MODEL_NAME)

    print("ğŸ“„ í…ìŠ¤íŠ¸ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘...")
    texts, metadata = load_text_files(TEXT_DIR)

    if not texts:
        print("âš ï¸ ì„ë² ë”©í•  ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    print("ğŸ“Š ì„ë² ë”© ìƒì„± ì¤‘...")
    embeddings = model.encode(texts, show_progress_bar=True)

    dim = embeddings.shape[1]
    index = faiss.IndexFlatL2(dim)
    index.add(embeddings)

    save_embeddings(index, metadata)
    print("âœ… ë¬¸ì„œ ì„ë² ë”© ì™„ë£Œ.")
